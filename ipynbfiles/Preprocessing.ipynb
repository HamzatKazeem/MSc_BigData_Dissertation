{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Raw Data to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_Tweets=pd.read_csv('data/rawdata/Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58045 entries, 0 to 58044\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   TweetsID       58045 non-null  int64 \n",
      " 1   TweetsText     58045 non-null  object\n",
      " 2   User_Location  45205 non-null  object\n",
      " 3   Date           58045 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_Tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetsID</th>\n",
       "      <th>TweetsText</th>\n",
       "      <th>User_Location</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1216910000000000000</td>\n",
       "      <td>We’re doing everything we can to get our stude...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24/10/2020 03:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40367314</td>\n",
       "      <td>https://t.co/jbGMWju8fn \\n\\n Thanks @RobinRobe...</td>\n",
       "      <td>Danny St.</td>\n",
       "      <td>24/10/2020 03:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TweetsID                                         TweetsText  \\\n",
       "0  1216910000000000000  We’re doing everything we can to get our stude...   \n",
       "1             40367314  https://t.co/jbGMWju8fn \\n\\n Thanks @RobinRobe...   \n",
       "\n",
       "  User_Location              Date  \n",
       "0           NaN  24/10/2020 03:29  \n",
       "1     Danny St.  24/10/2020 03:01  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_Tweets.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Data Statistics:    Gaining insight on the  Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for NULL VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TweetsID         False\n",
       "TweetsText       False\n",
       "User_Location     True\n",
       "Date             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_Tweets.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      "Test shows that there some null values in User_Location column. \n",
      "Hence the NULL entries were replaced with word 'LOCATION'\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(colored(\"\\nTest shows that there some null values in User_Location column. \\nHence the NULL entries were replaced with word 'LOCATION'\\n\",\"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_Tweets.loc[raw_Tweets['User_Location'].isnull()] #Showing the NULL values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the raw tweets using function  get_tweet_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets=get_tweet_content()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Function get_tweet_content() was used to clean the tweets.\n",
    "\n",
    "Steps carried out:\n",
    "\n",
    "Step1: Convert Tweets text to lower characters\n",
    "\n",
    "Step2: Remove Retweets, Remove URL, Replace User Mention and Hashtags, Replace positive and negative emoji`s\n",
    "\n",
    "Step3: Replace null values in user_location column with 'LOCATION'\\n\",\"blue\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TweetsID': '1216910000000000000',\n",
       " 'TweetsText': 'were doing everything we can to get our students back in school safely and quickly post hurricanelaura amp hurricanedelta and are thankful to those whove helped already but we need somebody who can get us tents or something asap catholictwitter ',\n",
       " 'User_Location': 'LOCATION',\n",
       " 'Date': '24/10/2020 03:29'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweets[0] #Sample of Clean Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_dataFrame=pd.DataFrame(Tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_data=Tweets_dataFrame.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21318 entries, 0 to 21317\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   TweetsID       21318 non-null  object\n",
      " 1   TweetsText     21318 non-null  object\n",
      " 2   User_Location  21318 non-null  object\n",
      " 3   Date           21318 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 666.3+ KB\n"
     ]
    }
   ],
   "source": [
    "processing_data.info() # 36, 727 Retweets and mull values were removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_data=processing_data.drop_duplicates(subset=['TweetsText'],keep='first') #Removing by TweetsText Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_data=processing_data.drop_duplicates(subset=['TweetsID'],keep='first') #Removing by TweetsText Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing check to show all duplicate tweets was removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetsID</th>\n",
       "      <th>TweetsText</th>\n",
       "      <th>User_Location</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [TweetsID, TweetsText, User_Location, Date]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing_data[processing_data.duplicated(['TweetsText'], keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetsID</th>\n",
       "      <th>TweetsText</th>\n",
       "      <th>User_Location</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [TweetsID, TweetsText, User_Location, Date]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing_data[processing_data.duplicated(['TweetsID'], keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetsID</th>\n",
       "      <th>TweetsText</th>\n",
       "      <th>User_Location</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14787</th>\n",
       "      <td>1327453151914504195</td>\n",
       "      <td>hey user_mention youre missing an excellent pr...</td>\n",
       "      <td>Starkville, MS</td>\n",
       "      <td>2020-11-14 03:27:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14788</th>\n",
       "      <td>1327470015055077378</td>\n",
       "      <td>power restored since halloween after zeta stru...</td>\n",
       "      <td>Biloxi, MS</td>\n",
       "      <td>2020-11-14 04:34:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14790</th>\n",
       "      <td>1329106772787744770</td>\n",
       "      <td>the adorablest sibling bond user_mention mohsi...</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>2020-11-18 16:58:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14791</th>\n",
       "      <td>1329107820969680898</td>\n",
       "      <td>a 10000 grant from the regions foundation will...</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "      <td>2020-11-18 17:02:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14792</th>\n",
       "      <td>1329112952381734912</td>\n",
       "      <td>tesla rivian and several ev manufacturers join...</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>2020-11-18 17:23:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  TweetsID                                         TweetsText  \\\n",
       "14787  1327453151914504195  hey user_mention youre missing an excellent pr...   \n",
       "14788  1327470015055077378  power restored since halloween after zeta stru...   \n",
       "14790  1329106772787744770  the adorablest sibling bond user_mention mohsi...   \n",
       "14791  1329107820969680898  a 10000 grant from the regions foundation will...   \n",
       "14792  1329112952381734912  tesla rivian and several ev manufacturers join...   \n",
       "\n",
       "         User_Location                 Date  \n",
       "14787   Starkville, MS  2020-11-14 03:27:48  \n",
       "14788       Biloxi, MS  2020-11-14 04:34:49  \n",
       "14790         LOCATION  2020-11-18 16:58:42  \n",
       "14791  New Orleans, LA  2020-11-18 17:02:52  \n",
       "14792    San Diego, CA  2020-11-18 17:23:16  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing_data.tail() # User_Location for serial no 14790 now reads 'LOCATION'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8766 entries, 0 to 14792\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   TweetsID       8766 non-null   object\n",
      " 1   TweetsText     8766 non-null   object\n",
      " 2   User_Location  8766 non-null   object\n",
      " 3   Date           8766 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 342.4+ KB\n"
     ]
    }
   ],
   "source": [
    "processing_data.info() #Distincts Tweets is 9,130. 9,255 duplicates have been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving cleaned Tweets to CSV file 8766 distinct tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_data.to_csv('data/proData/processdata.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corresponding functions used in above experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweets):\n",
    "    \n",
    "    #for twit in tweets:      \n",
    "    # Convert to lower case\n",
    "    tweet= tweets.lower()\n",
    "    # Replaces URLs with the word URL\n",
    "    tweet = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', ' URL ', tweet)\n",
    "    # Replace @handle with the word USER_MENTION\n",
    "    tweet = re.sub(r'@[\\S]+', 'user_mention', tweet)\n",
    "    # Replaces #hashtag with hashtag\n",
    "    tweet = re.sub(r'#(\\S+)', r' \\1 ', tweet)\n",
    "    # Remove RT (retweet)\n",
    "    tweet = re.sub(r'\\brt\\b', 'RT', tweet)\n",
    "    # Replace 2+ dots with space\n",
    "    tweet = re.sub(r'\\.{2,}', ' ', tweet)\n",
    "    # Strip space, \" and ' from tweet\n",
    "    tweet = re.sub(r'[^\\w\\s]','',tweet)\n",
    "    # Replace emojis with either EMO_POS or EMO_NEG\n",
    "    tweet = handle_emojis(tweet)\n",
    "    # Replace multiple spaces with a single space\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    #tweet=[char for char in tweet if char not in string.punctuation]\n",
    "    words = ''.join(tweet)\n",
    "    tweet = words\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_emojis(tweet):\n",
    "    # Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
    "    tweet = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))', ' EMO_POS ', tweet)\n",
    "    # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
    "    tweet = re.sub(r'(:\\s?D|:-D|x-?D|X-?D)', ' EMO_POS ', tweet)\n",
    "    # Love -- <3, :*\n",
    "    tweet = re.sub(r'(<3|:\\*)', ' EMO_POS ', tweet)\n",
    "    # Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
    "    tweet = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' EMO_POS ', tweet)\n",
    "    # Sad -- :-(, : (, :(, ):, )-:\n",
    "    tweet = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', ' EMO_NEG ', tweet)\n",
    "    # Cry -- :,(, :'(, :\"(\n",
    "    tweet = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' EMO_NEG ', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def get_tweet_content():\n",
    "    #import csv\n",
    "    from datetime import datetime\n",
    "    lex1=[]\n",
    "    \n",
    "    reader = csv.reader(open('data/rawdata/Tweets.csv', 'r',encoding=\"utf8\"))\n",
    "    csvreader = csv.reader(reader)\n",
    "    next(reader)\n",
    "    for line in reader:\n",
    "        lex={}\n",
    "        TweetsID, TweetsText,User_Location,Date = line\n",
    "        lex['TweetsID']=str(TweetsID)\n",
    "        lex['TweetsText']=TweetsText\n",
    "        lex['User_Location']=User_Location\n",
    "        lex['Date']=Date\n",
    "    # ignore retweets \n",
    "        if len(lex['User_Location']) < 1:        \n",
    "            lex['User_Location']='LOCATION'\n",
    "        if lex['TweetsText'].startswith('RT') or len(lex['TweetsText']) < 1:\n",
    "                pass \n",
    "        else:\n",
    "            lex['TweetsText']=process_tweet(TweetsText)      \n",
    "            lex1.append(lex)\n",
    "    \n",
    "    return lex1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
